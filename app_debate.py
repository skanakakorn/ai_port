import os
import json
import time
import re
import streamlit as st
import requests

# ============== LLM Adapter Function ===================
def call_llm_debate(messages, provider=None, model=None, temperature=0.7, max_tokens=300):
    """
    Call LLM with messages list. Supports GROQ and OPENAI.
    messages: list of dicts with "role" and "content" keys
    """
    if provider is None:
        provider = os.getenv("LLM_PROVIDER", "GROQ").upper()
    if model is None:
        model = os.getenv("LLM_MODEL_ID", "openai/gpt-oss-120b")
    
    if provider == "OPENAI":
        try:
            from openai import OpenAI
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            # Newer OpenAI models use max_completion_tokens instead of max_tokens
            # Some newer models only support default temperature (1.0)
            params = {
                "model": model,
                "messages": messages,
                "max_completion_tokens": max_tokens,
            }
            # Try with temperature first (if not default)
            if temperature != 1.0:
                params["temperature"] = temperature
            
            try:
                resp = client.chat.completions.create(**params)
                content = resp.choices[0].message.content.strip()
                # Check if response was cut off (finish_reason == "length")
                if resp.choices[0].finish_reason == "length":
                    # Response was cut off due to token limit
                    content += "\n\n[à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¸±à¸”à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸–à¸¶à¸‡à¸‚à¸µà¸”à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§]"
                return content
            except Exception as temp_error:
                # If temperature is not supported, retry without it
                error_str = str(temp_error)
                if "temperature" in error_str.lower() and "unsupported" in error_str.lower():
                    params.pop("temperature", None)  # Remove temperature if present
                    resp = client.chat.completions.create(**params)
                    content = resp.choices[0].message.content.strip()
                    if resp.choices[0].finish_reason == "length":
                        content += "\n\n[à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¸±à¸”à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸–à¸¶à¸‡à¸‚à¸µà¸”à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§]"
                    return content
                else:
                    raise temp_error
        except Exception as e:
            return f"[LLM error OPENAI: {e}]"
    
    elif provider == "GROQ":
        try:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {os.getenv('GROQ_API_KEY')}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens,
            }
            r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
            r.raise_for_status()
            data = r.json()
            content = data["choices"][0]["message"]["content"].strip()
            # Check if response was cut off (finish_reason == "length")
            if data["choices"][0].get("finish_reason") == "length":
                # Response was cut off due to token limit
                content += "\n\n[à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¸±à¸”à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸ˆà¸²à¸à¸–à¸¶à¸‡à¸‚à¸µà¸”à¸ˆà¸³à¸à¸±à¸”à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§]"
            return content
        except Exception as e:
            return f"[LLM error GROQ: {e}]"
    
    else:
        return "[DUMMY LLM] This is a placeholder response. Set LLM_PROVIDER and API key."

# ============== Agent System Prompts ===================
VALUE_INVESTOR_SYSTEM = """à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸™à¸±à¸à¸¥à¸‡à¸—à¸¸à¸™à¹à¸šà¸š Value Investor à¸—à¸µà¹ˆà¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¹ƒà¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸«à¸¸à¹‰à¸™
à¸„à¸¸à¸“à¹€à¸™à¹‰à¸™à¸—à¸µà¹ˆ:
- à¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¸žà¸·à¹‰à¸™à¸à¸²à¸™ (fundamentals) à¹€à¸Šà¹ˆà¸™ P/E ratio, P/B ratio, book value
- à¹€à¸‡à¸´à¸™à¸›à¸±à¸™à¸œà¸¥ (dividends) à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¸„à¸‡à¸—à¸²à¸‡à¸à¸²à¸£à¹€à¸‡à¸´à¸™
- à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸£à¸²à¸„à¸²à¸—à¸µà¹ˆà¸•à¹ˆà¸³à¸à¸§à¹ˆà¸²à¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¸ˆà¸£à¸´à¸‡ (undervalued)
- à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸£à¸°à¸¢à¸°à¸¢à¸²à¸§à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¹€à¸ªà¸µà¹ˆà¸¢à¸‡à¸•à¹ˆà¸³
- à¸‡à¸šà¸à¸²à¸£à¹€à¸‡à¸´à¸™à¸—à¸µà¹ˆà¹à¸‚à¹‡à¸‡à¹à¸à¸£à¹ˆà¸‡à¹à¸¥à¸°à¸«à¸™à¸µà¹‰à¸ªà¸´à¸™à¸•à¹ˆà¸³

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸£à¸°à¸Šà¸±à¸šà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸¡à¸µà¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸žà¸¹à¸”à¹à¸šà¸šà¸”à¹‡à¸­à¸à¹€à¸•à¸­à¸£à¹Œà¸™à¸´à¹€à¸§à¸¨ à¹€à¸™à¹‰à¸™à¹€à¸«à¸•à¸¸à¸œà¸¥à¹€à¸Šà¸´à¸‡à¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¸„à¸‡
à¸ªà¸³à¸„à¸±à¸: 
- à¸•à¸­à¸šà¹‚à¸”à¸¢à¸•à¸£à¸‡à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸•à¸±à¸§à¹€à¸­à¸‡à¸«à¸£à¸·à¸­à¹ƒà¸ªà¹ˆà¸„à¸³à¸™à¸³à¸«à¸™à¹‰à¸²à¸§à¹ˆà¸² "Value Investor" à¹ƒà¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
- à¸­à¸¢à¹ˆà¸²à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™à¸à¸±à¸šà¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¹€à¸„à¸¢à¸žà¸¹à¸”à¹„à¸›à¹à¸¥à¹‰à¸§à¹ƒà¸™à¸£à¸­à¸šà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²
- à¸•à¸­à¸šà¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸µà¹ˆ Growth Investor à¹€à¸žà¸´à¹ˆà¸‡à¸à¸¥à¹ˆà¸²à¸§à¸¡à¸² à¹à¸¥à¸°à¹€à¸ªà¸™à¸­à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ"""

GROWTH_INVESTOR_SYSTEM = """à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸™à¸±à¸à¸¥à¸‡à¸—à¸¸à¸™à¹à¸šà¸š Growth Investor à¸—à¸µà¹ˆà¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¹ƒà¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸«à¸¸à¹‰à¸™
à¸„à¸¸à¸“à¹€à¸™à¹‰à¸™à¸—à¸µà¹ˆ:
- à¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•à¸‚à¸­à¸‡à¸£à¸²à¸¢à¹„à¸”à¹‰ (revenue growth) à¹à¸¥à¸°à¸à¸³à¹„à¸£
- à¸à¸²à¸£à¸‚à¸¢à¸²à¸¢à¸•à¸±à¸§à¸‚à¸­à¸‡à¸•à¸¥à¸²à¸”à¹à¸¥à¸°à¸™à¸§à¸±à¸•à¸à¸£à¸£à¸¡
- à¸¨à¸±à¸à¸¢à¸ à¸²à¸žà¹ƒà¸™à¸­à¸™à¸²à¸„à¸•à¹à¸¥à¸°à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸­à¸¸à¸•à¸ªà¸²à¸«à¸à¸£à¸£à¸¡
- à¸à¸²à¸£à¸¥à¸‡à¸—à¸¸à¸™à¹ƒà¸™à¸šà¸£à¸´à¸©à¸±à¸—à¸—à¸µà¹ˆà¸à¸³à¸¥à¸±à¸‡à¹€à¸•à¸´à¸šà¹‚à¸•à¸­à¸¢à¹ˆà¸²à¸‡à¸£à¸§à¸”à¹€à¸£à¹‡à¸§
- à¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¸•à¸¥à¸²à¸”à¸—à¸µà¹ˆà¹€à¸žà¸´à¹ˆà¸¡à¸‚à¸¶à¹‰à¸™ (market expansion)

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸£à¸°à¸Šà¸±à¸šà¹à¸¥à¸°à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¹€à¸™à¹‰à¸™à¹‚à¸­à¸à¸²à¸ªà¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•à¹à¸¥à¸°à¸¨à¸±à¸à¸¢à¸ à¸²à¸ž
à¸ªà¸³à¸„à¸±à¸: 
- à¸•à¸­à¸šà¹‚à¸”à¸¢à¸•à¸£à¸‡à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸•à¸±à¸§à¹€à¸­à¸‡à¸«à¸£à¸·à¸­à¹ƒà¸ªà¹ˆà¸„à¸³à¸™à¸³à¸«à¸™à¹‰à¸²à¸§à¹ˆà¸² "Growth Investor" à¹ƒà¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡
- à¸­à¸¢à¹ˆà¸²à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™à¸à¸±à¸šà¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¹€à¸„à¸¢à¸žà¸¹à¸”à¹„à¸›à¹à¸¥à¹‰à¸§à¹ƒà¸™à¸£à¸­à¸šà¸à¹ˆà¸­à¸™à¸«à¸™à¹‰à¸²
- à¸•à¸­à¸šà¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸µà¹ˆ Value Investor à¹€à¸žà¸´à¹ˆà¸‡à¸à¸¥à¹ˆà¸²à¸§à¸¡à¸² à¹à¸¥à¸°à¹€à¸ªà¸™à¸­à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆ"""

# ============== Debate Engine ===================
class DebateEngine:
    def __init__(self, question, provider, model, max_duration=15):
        self.question = question
        self.provider = provider
        self.model = model
        self.max_duration = max_duration
        self.start_time = None
        self.messages = []
        self.debate_active = False
        self.debate_history = []
        
    def get_elapsed_time(self):
        if self.start_time is None:
            return 0
        return time.time() - self.start_time
    
    def get_remaining_time(self):
        return max(0, self.max_duration - self.get_elapsed_time())
    
    def is_time_up(self):
        return self.get_elapsed_time() >= self.max_duration
    
    def add_message(self, role, content, agent_name):
        """Add message to debate history"""
        self.debate_history.append({
            "role": role,
            "content": content,
            "agent_name": agent_name,
            "timestamp": time.time() - self.start_time if self.start_time else 0
        })
    
    def get_agent_response(self, agent_name, agent_system, conversation_history):
        """Get response from an agent"""
        # Determine the other agent's name
        other_agent_name = "Growth Investor" if agent_name == "Value Investor" else "Value Investor"
        
        messages = [
            {"role": "system", "content": agent_system},
            {"role": "user", "content": f"à¸„à¸³à¸–à¸²à¸¡: {self.question}\n\nà¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸•à¸­à¸šà¹ƒà¸™à¸à¸²à¸™à¸°{agent_name} à¹à¸¥à¸°à¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸à¸±à¸š{other_agent_name}"}
        ]
        
        # Extract what this agent has already said (to avoid repetition)
        my_previous_points = []
        other_agent_last_points = []
        
        if conversation_history:
            for msg in conversation_history:
                if msg["role"] == "assistant":
                    speaker = msg.get("agent_name", "Unknown")
                    if speaker == agent_name:
                        my_previous_points.append(msg['content'])
                    elif speaker == other_agent_name:
                        other_agent_last_points.append(msg['content'])
        
        # Add conversation history with agent names for context
        if conversation_history:
            history_text = "à¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ:\n"
            for msg in conversation_history:
                if msg["role"] == "assistant":
                    speaker = msg.get("agent_name", "Unknown")
                    history_text += f"[{speaker}]: {msg['content']}\n\n"
            messages.append({
                "role": "user",
                "content": history_text
            })
        
        # Build explicit instruction to avoid repetition
        instruction_parts = [
            f"à¸•à¸­à¸™à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸•à¸²à¸‚à¸­à¸‡à¸„à¸¸à¸“à¹à¸¥à¹‰à¸§ ({agent_name}) à¹ƒà¸«à¹‰à¸•à¸­à¸šà¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸à¸±à¸š{other_agent_name}"
        ]
        
        # If this agent has spoken before, explicitly list what they've already said
        if my_previous_points:
            instruction_parts.append(f"\nâš ï¸ à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¹€à¸„à¸¢à¸žà¸¹à¸”à¹„à¸›à¹à¸¥à¹‰à¸§ (à¸«à¹‰à¸²à¸¡à¸‹à¹‰à¸³!):")
            for i, point in enumerate(my_previous_points[-2:], 1):  # Show last 2 responses
                # Truncate if too long
                truncated = point[:200] + "..." if len(point) > 200 else point
                instruction_parts.append(f"  {i}. {truncated}")
        
        # If other agent just spoke, emphasize responding to their latest points
        if other_agent_last_points:
            latest_other = other_agent_last_points[-1]
            instruction_parts.append(f"\nðŸŽ¯ {other_agent_name} à¹€à¸žà¸´à¹ˆà¸‡à¸à¸¥à¹ˆà¸²à¸§à¸§à¹ˆà¸²:")
            instruction_parts.append(f"  \"{latest_other[:300]}{'...' if len(latest_other) > 300 else ''}\"")
            instruction_parts.append(f"\nà¸„à¸¸à¸“à¸•à¹‰à¸­à¸‡à¸•à¸­à¸šà¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¹‚à¸”à¸¢à¹€à¸‰à¸žà¸²à¸°!")
        
        instruction_parts.extend([
            "\nà¸„à¸³à¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸„à¸±à¸:",
            "- à¸­à¸¢à¹ˆà¸²à¸‹à¹‰à¸³à¸‹à¹‰à¸­à¸™à¸à¸±à¸šà¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¹€à¸„à¸¢à¸žà¸¹à¸”à¹„à¸›à¹à¸¥à¹‰à¸§ (à¸”à¸¹à¸£à¸²à¸¢à¸à¸²à¸£à¸”à¹‰à¸²à¸™à¸šà¸™)",
            "- à¸•à¸­à¸šà¹‚à¸•à¹‰à¹à¸¢à¹‰à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸µà¹ˆ" + other_agent_name + "à¹€à¸žà¸´à¹ˆà¸‡à¸à¸¥à¹ˆà¸²à¸§à¸¡à¸²",
            "- à¹€à¸ªà¸™à¸­à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¹ƒà¸«à¸¡à¹ˆà¸«à¸£à¸·à¸­à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹€à¸„à¸¢à¸žà¸¹à¸”",
            "- à¸•à¸­à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹à¸¥à¸°à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ (4-6 à¸›à¸£à¸°à¹‚à¸¢à¸„)",
            "- à¸•à¸­à¸šà¹‚à¸”à¸¢à¸•à¸£à¸‡à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸•à¸±à¸§à¹€à¸­à¸‡"
        ])
        
        messages.append({
            "role": "user",
            "content": "\n".join(instruction_parts)
        })
        
        response = call_llm_debate(
            messages,
            provider=self.provider,
            model=self.model,
            temperature=0.4,  # Increased from 0.2 to add more variation and reduce repetition
            max_tokens=1000  # Increased from 500 to prevent text cutoff
        )
        
        # Clean up response - remove any agent name prefixes that might have been added
        response = response.strip()
        # Remove patterns like "Value Investor:", "Growth Investor:", "Value Investor (à¸•à¸­à¸šà¹‚à¸•à¹‰):", etc.
        # Also handle Thai variations
        patterns = [
            r'^(Value Investor|Growth Investor)\s*[:\-\(].*?\)?\s*',  # English with punctuation
            r'^(Value Investor|Growth Investor)\s+',  # English with space
            r'^.*?Value Investor.*?[:\-]\s*',  # Any text before "Value Investor:"
            r'^.*?Growth Investor.*?[:\-]\s*',  # Any text before "Growth Investor:"
        ]
        for pattern in patterns:
            response = re.sub(pattern, '', response, flags=re.IGNORECASE)
        response = response.strip()
        
        return response
    
    def run_debate(self):
        """Run the debate for max_duration seconds, with max 3 turns per side"""
        self.start_time = time.time()
        self.debate_active = True
        
        # Track turns for each agent (max 3 each)
        value_turns = 0
        growth_turns = 0
        max_turns_per_side = 3
        
        # Initial messages from both agents (counts as turn 1 for each)
        value_msg = self.get_agent_response(
            "Value Investor",
            VALUE_INVESTOR_SYSTEM,
            []
        )
        self.add_message("assistant", value_msg, "Value Investor")
        value_turns += 1
        time.sleep(1)  # Pause 1 second after Value Investor's response
        
        growth_msg = self.get_agent_response(
            "Growth Investor",
            GROWTH_INVESTOR_SYSTEM,
            self.debate_history
        )
        self.add_message("assistant", growth_msg, "Growth Investor")
        growth_turns += 1
        time.sleep(1)  # Pause 1 second after Growth Investor's response
        
        # Alternate turns until time is up or either side reaches max turns
        turn = 0
        while not self.is_time_up() and self.debate_active:
            # Check if either side has reached max turns
            if value_turns >= max_turns_per_side and growth_turns >= max_turns_per_side:
                break
            
            remaining = self.get_remaining_time()
            if remaining < 3:  # Not enough time for another turn
                break
            
            # Alternate between agents, but only if they haven't reached max turns
            if turn % 2 == 0:
                # Value Investor's turn
                if value_turns < max_turns_per_side:
                    response = self.get_agent_response(
                        "Value Investor",
                        VALUE_INVESTOR_SYSTEM,
                        self.debate_history
                    )
                    self.add_message("assistant", response, "Value Investor")
                    value_turns += 1
                    time.sleep(1)  # Pause 1 second after Value Investor's response
                elif growth_turns < max_turns_per_side:
                    # Skip Value Investor if they've reached max, continue with Growth
                    turn += 1
                    continue
                else:
                    break
            else:
                # Growth Investor's turn
                if growth_turns < max_turns_per_side:
                    response = self.get_agent_response(
                        "Growth Investor",
                        GROWTH_INVESTOR_SYSTEM,
                        self.debate_history
                    )
                    self.add_message("assistant", response, "Growth Investor")
                    growth_turns += 1
                    time.sleep(1)  # Pause 1 second after Growth Investor's response
                elif value_turns < max_turns_per_side:
                    # Skip Growth Investor if they've reached max, continue with Value
                    turn += 1
                    continue
                else:
                    break
            
            turn += 1
        
        self.debate_active = False
        return self.debate_history
    
    def generate_summary(self):
        """Generate summary/conclusion of the debate"""
        # Build conversation summary
        conversation_text = f"à¸„à¸³à¸–à¸²à¸¡: {self.question}\n\n"
        for msg in self.debate_history:
            conversation_text += f"[{msg['agent_name']}]: {msg['content']}\n\n"
        
        summary_prompt = f"""à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µà¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡ Value Investor à¹à¸¥à¸° Growth Investor à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸„à¸³à¸–à¸²à¸¡: {self.question}

à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ:
{conversation_text}

à¹ƒà¸«à¹‰à¸ªà¸£à¸¸à¸›à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸«à¸¥à¸±à¸à¸—à¸µà¹ˆà¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸à¹ˆà¸²à¸¢à¹€à¸ªà¸™à¸­à¸­à¸¢à¹ˆà¸²à¸‡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹à¸¥à¸°à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ à¹‚à¸”à¸¢à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸‚à¸­à¸‡à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸ªà¹ˆà¸§à¸™à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™ (à¸ˆà¸³à¸™à¸§à¸™à¸„à¸³/à¸›à¸£à¸°à¹‚à¸¢à¸„à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™):

**1. à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸‚à¸­à¸‡ Value Investor**
à¸­à¸˜à¸´à¸šà¸²à¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” à¸›à¸£à¸°à¸¡à¸²à¸“ 4-6 à¸›à¸£à¸°à¹‚à¸¢à¸„ (à¹€à¸™à¹‰à¸™à¸¡à¸¹à¸¥à¸„à¹ˆà¸²à¸žà¸·à¹‰à¸™à¸à¸²à¸™, à¸„à¸§à¸²à¸¡à¸¡à¸±à¹ˆà¸™à¸„à¸‡, à¸‡à¸šà¸à¸²à¸£à¹€à¸‡à¸´à¸™) à¸•à¹‰à¸­à¸‡à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹à¸¥à¸°à¸ˆà¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¹ƒà¸«à¹‰à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

**2. à¸¡à¸¸à¸¡à¸¡à¸­à¸‡à¸‚à¸­à¸‡ Growth Investor**
à¸­à¸˜à¸´à¸šà¸²à¸¢à¸­à¸¢à¹ˆà¸²à¸‡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” à¸›à¸£à¸°à¸¡à¸²à¸“ 4-6 à¸›à¸£à¸°à¹‚à¸¢à¸„ (à¹€à¸™à¹‰à¸™à¸à¸²à¸£à¹€à¸•à¸´à¸šà¹‚à¸•, à¸¨à¸±à¸à¸¢à¸ à¸²à¸ž, à¸™à¸§à¸±à¸•à¸à¸£à¸£à¸¡) à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸š Value Investor à¹à¸¥à¸°à¸ˆà¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¹ƒà¸«à¹‰à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

**3. à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸—à¸µà¹ˆà¸ªà¸¡à¸”à¸¸à¸¥**
à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹à¸¥à¸°à¹ƒà¸«à¹‰à¸„à¸³à¹à¸™à¸°à¸™à¸³ (4-6 à¸›à¸£à¸°à¹‚à¸¢à¸„) à¸•à¹‰à¸­à¸‡à¸ˆà¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¹ƒà¸«à¹‰à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

âš ï¸ à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸: 
- à¹ƒà¸«à¹‰à¸—à¸±à¹‰à¸‡ Value Investor à¹à¸¥à¸° Growth Investor à¸¡à¸µà¸ˆà¸³à¸™à¸§à¸™à¸„à¸³à¹à¸¥à¸°à¸›à¸£à¸°à¹‚à¸¢à¸„à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™
- à¸•à¹‰à¸­à¸‡à¸•à¸­à¸šà¸„à¸£à¸šà¸—à¸±à¹‰à¸‡ 3 à¸ªà¹ˆà¸§à¸™ (Value Investor, Growth Investor, à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›)
- à¸•à¹‰à¸­à¸‡à¸ˆà¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¹‰à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ à¸­à¸¢à¹ˆà¸²à¸•à¸±à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸à¸¥à¸²à¸‡à¸„à¸±à¸™
- à¸­à¸¢à¹ˆà¸²à¸«à¸¢à¸¸à¸”à¸à¸¥à¸²à¸‡à¸›à¸£à¸°à¹‚à¸¢à¸„ à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™à¹ƒà¸«à¹‰à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ à¸­à¸¢à¹ˆà¸²à¸•à¸±à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸à¸¥à¸²à¸‡à¸„à¸±à¸™"""
        
        messages = [
            {"role": "system", "content": "à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µà¸à¸²à¸£à¸¥à¸‡à¸—à¸¸à¸™ à¹ƒà¸«à¹‰à¸ªà¸£à¸¸à¸›à¸­à¸¢à¹ˆà¸²à¸‡à¹€à¸›à¹‡à¸™à¸à¸¥à¸²à¸‡ à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸à¹ˆà¸²à¸¢ à¹‚à¸”à¸¢à¹ƒà¸«à¹‰à¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¸‚à¸­à¸‡à¸—à¸±à¹‰à¸‡à¸ªà¸­à¸‡à¸ªà¹ˆà¸§à¸™ (Value Investor à¹à¸¥à¸° Growth Investor) à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™à¸¡à¸²à¸ à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸: à¸•à¹‰à¸­à¸‡à¸•à¸­à¸šà¸„à¸£à¸šà¸—à¸±à¹‰à¸‡ 3 à¸ªà¹ˆà¸§à¸™ (Value Investor, Growth Investor, à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›) à¹à¸¥à¸°à¸•à¹‰à¸­à¸‡à¸ˆà¸šà¸›à¸£à¸°à¹‚à¸¢à¸„à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¹‰à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ à¸­à¸¢à¹ˆà¸²à¸•à¸±à¸”à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸à¸¥à¸²à¸‡à¸„à¸±à¸™ à¸­à¸¢à¹ˆà¸²à¸«à¸¢à¸¸à¸”à¸à¸¥à¸²à¸‡à¸›à¸£à¸°à¹‚à¸¢à¸„ à¸•à¹‰à¸­à¸‡à¹€à¸‚à¸µà¸¢à¸™à¹ƒà¸«à¹‰à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ"},
            {"role": "user", "content": summary_prompt}
        ]
        
        summary = call_llm_debate(
            messages,
            provider=self.provider,
            model=self.model,
            temperature=0.5,
            max_tokens=4000
        )
        return summary

# ============== Streamlit UI ===================
st.set_page_config(
    page_title="AI Debate: Value vs Growth Investor",
    page_icon="ðŸ’¬",
    layout="wide"
)

st.title("ðŸ’¬ AI Debate: Value Investor vs Growth Investor")
st.caption("à¹ƒà¸«à¹‰ AI à¸ªà¸­à¸‡à¸•à¸±à¸§à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µà¸à¸±à¸™à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸à¸²à¸£à¸¥à¸‡à¸—à¸¸à¸™ - à¸£à¸°à¸¢à¸°à¹€à¸§à¸¥à¸² 15 à¸§à¸´à¸™à¸²à¸—à¸µ")

# Sidebar Configuration
st.sidebar.header("âš™ï¸ à¸à¸²à¸£à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²")

provider_options = ["GROQ", "OPENAI"]
default_provider = os.getenv("LLM_PROVIDER", "GROQ").upper()
if default_provider not in provider_options:
    default_provider = "GROQ"

selected_provider = st.sidebar.selectbox(
    "à¹€à¸¥à¸·à¸­à¸ LLM Provider",
    options=provider_options,
    index=provider_options.index(default_provider) if default_provider in provider_options else 0
)

# Model selection based on provider
if selected_provider == "GROQ":
    default_model = os.getenv("LLM_MODEL_ID", "openai/gpt-oss-120b")
    model_options = ["openai/gpt-oss-120b", "llama-3.1-8b-instruct", "llama-3.1-70b-instruct"]
    if default_model not in model_options:
        model_options.insert(0, default_model)
    selected_model = st.sidebar.selectbox(
        "à¹€à¸¥à¸·à¸­à¸ Model (Groq)",
        options=model_options,
        index=0
    )
else:  # OPENAI
    default_model = os.getenv("LLM_MODEL_ID", "gpt-4o-mini")
    model_options = ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"]
    if default_model not in model_options:
        model_options.insert(0, default_model)
    selected_model = st.sidebar.selectbox(
        "à¹€à¸¥à¸·à¸­à¸ Model (OpenAI)",
        options=model_options,
        index=0
    )

# API Key status
api_key_name = f"{selected_provider}_API_KEY"
api_key = os.getenv(api_key_name)
if not api_key:
    st.sidebar.warning(f"âš ï¸ à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² {api_key_name} à¹ƒà¸™ environment variables")
else:
    st.sidebar.success(f"âœ… {selected_provider} API Key à¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™")

st.sidebar.divider()
st.sidebar.markdown("**à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸„à¸³à¸–à¸²à¸¡:**")
st.sidebar.markdown("- AI à¸•à¸±à¸§à¹„à¸«à¸™à¸ˆà¸°à¸Šà¸™à¸°à¹ƒà¸™à¸›à¸µ 2026: NVIDIA à¸«à¸£à¸·à¸­ BYD?")
st.sidebar.markdown("- à¸„à¸§à¸£à¸¥à¸‡à¸—à¸¸à¸™à¹ƒà¸™à¸«à¸¸à¹‰à¸™à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸«à¸£à¸·à¸­à¸«à¸¸à¹‰à¸™à¸žà¸¥à¸±à¸‡à¸‡à¸²à¸™?")
st.sidebar.markdown("- TSMC vs Intel: à¹ƒà¸„à¸£à¸ˆà¸°à¸”à¸µà¸à¸§à¹ˆà¸²à¹ƒà¸™à¸£à¸°à¸¢à¸°à¸¢à¸²à¸§?")

# Main UI
st.divider()

# Initialize session state
if "debate_history" not in st.session_state:
    st.session_state.debate_history = []
if "debate_engine" not in st.session_state:
    st.session_state.debate_engine = None
if "debate_running" not in st.session_state:
    st.session_state.debate_running = False
if "debate_summary" not in st.session_state:
    st.session_state.debate_summary = None

# Question input
question = st.text_input(
    "ðŸ’­ à¹ƒà¸ªà¹ˆà¸„à¸³à¸–à¸²à¸¡à¸‚à¸­à¸‡à¸„à¸¸à¸“:",
    placeholder="à¹€à¸Šà¹ˆà¸™: AI à¸•à¸±à¸§à¹„à¸«à¸™à¸ˆà¸°à¸Šà¸™à¸°à¹ƒà¸™à¸›à¸µ 2026: NVIDIA à¸«à¸£à¸·à¸­ BYD?",
    key="question_input"
)

col1, col2 = st.columns([1, 4])
with col1:
    start_button = st.button("ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ", type="primary", disabled=st.session_state.debate_running)
with col2:
    if st.session_state.debate_running:
        st.info("â³ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ...")

# Chat display area
chat_container = st.container()

# Display chat messages
def display_chat_messages():
    """Display all chat messages in bubble format"""
    with chat_container:
        if st.session_state.debate_history:
            for msg in st.session_state.debate_history:
                agent_name = msg.get("agent_name", "Unknown")
                content = msg.get("content", "")
                timestamp = msg.get("timestamp", 0)
                
                if agent_name == "Value Investor":
                    with st.chat_message("user", avatar="ðŸ’°"):
                        st.markdown(f"**Value Investor:** {content}")
                        st.caption(f"à¹€à¸§à¸¥à¸²: {timestamp:.1f}s")
                elif agent_name == "Growth Investor":
                    with st.chat_message("assistant", avatar="ðŸš€"):
                        st.markdown(f"**Growth Investor:** {content}")
                        st.caption(f"à¹€à¸§à¸¥à¸²: {timestamp:.1f}s")

# Timer display (will be shown during debate)

# Run debate when button is clicked
if start_button and question and not st.session_state.debate_running:
    if not api_key:
        st.error(f"âš ï¸ à¸à¸£à¸¸à¸“à¸²à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸² {api_key_name} à¹ƒà¸™ environment variables")
    else:
        st.session_state.debate_running = True
        st.session_state.debate_history = []
        st.session_state.debate_summary = None
        
        # Create debate engine
        engine = DebateEngine(question, selected_provider, selected_model, max_duration=15)
        st.session_state.debate_engine = engine
        
        # Run debate
        try:
            with st.spinner("â³ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ... (15 à¸§à¸´à¸™à¸²à¸—à¸µ)"):
                history = engine.run_debate()
                st.session_state.debate_history = history
            
            # Generate summary
            with st.spinner("ðŸ“ à¸à¸³à¸¥à¸±à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸¸à¸›..."):
                summary = engine.generate_summary()
                st.session_state.debate_summary = summary
            
        except Exception as e:
            st.error(f"à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {e}")
            import traceback
            st.code(traceback.format_exc())
        finally:
            st.session_state.debate_running = False
        
        st.rerun()

# Display existing messages
display_chat_messages()

# Show summary if available
if st.session_state.debate_summary:
    st.divider()
    st.subheader("ðŸ“ à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¹‚à¸•à¹‰à¸§à¸²à¸—à¸µ")
    st.info(st.session_state.debate_summary)

